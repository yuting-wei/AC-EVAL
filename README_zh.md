<p align="center"> <img src="resources/title.png" style="width: 100%;" id="title-icon">       </p>

<p align="center">
  â¬ <a href="#data" target="_blank">æ•°æ®</a> â€¢   ğŸ“ƒ <a href="http://arxiv.org/abs/2403.06574" target="_blank">è®ºæ–‡</a>  â€¢   ğŸ† <a href="https://github.com/yuting-wei/AC-EVAL/tree/main/#leaderboard" target="_blank">æ’è¡Œæ¦œ</a>  <br>  <a href="https://github.com/yuting-wei/AC-EVAL/tree/main/README_zh.md">   ä¸­æ–‡</a> | <a href="https://github.com/yuting-wei/AC-EVAL/tree/main/README.md">English 
</p>


AC-EVAL æä¾›äº†ä¸€ä¸ªé¢å‘ä¸­å›½å¤ä»£è¯­è¨€çš„å¤§è¯­è¨€æ¨¡å‹å…¨é¢è¯„ä¼°å¥—ä»¶ï¼Œæ¶µç›–äº†ä»å…ˆç§¦æ—¶æœŸåˆ°æ¸…æœçš„å„ä¸ªæ—¶ä»£ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬ 3245 é“å¤šé¡¹é€‰æ‹©é¢˜ï¼Œè¦†ç›–äº† 3 ä¸ªéš¾åº¦ç­‰çº§å’Œ 13 ä¸ªä¸åŒçš„ä»»åŠ¡ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚æ›´å¤šç»†èŠ‚è¯·æŸ¥é˜…æˆ‘ä»¬çš„[è®ºæ–‡](http://arxiv.org/abs/2403.06574)ã€‚

<img src="resources/overview.png" style="zoom: 80%;" >


æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è¯„ä¼°å’Œæ¨è¿›å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£å’Œå¤„ç†å¤ä»£æ±‰è¯­è¯­è¨€å’ŒçŸ¥è¯†æ–¹é¢èƒ½åŠ›ã€‚

## æ’è¡Œæ¦œ
æˆ‘ä»¬æ’è¡Œæ¦œå®šæœŸæ›´æ–°ã€‚ä¸‹é¢å±•ç¤ºäº†å„ç§æ¨¡å‹åœ¨answer-only (AO)å’Œ chain-of-thought (COT)è®¾ç½®ä¸‹çš„zero-shotå’Œfive-shotçš„å‡†ç¡®ç‡ã€‚ç»†åˆ†ç»“æœå¯åœ¨[breakdown_results.xlsx](https://github.com/yuting-wei/AC-EVAL/tree/main/breakdown_results.xlsx)æŸ¥çœ‹ã€‚

#### Zero-shot AO
| æ¨¡å‹          | åŸºç¡€å†å²çŸ¥è¯† | çŸ­æ–‡æœ¬ç†è§£ | é•¿æ–‡æœ¬ç†è§£ | å¹³å‡å€¼ |
|----------------|:------------------------------:|:--------------------------:|:-------------------------:|:---------:|
| ERNIE-Bot 4.0  | 77.54                        | 68.11                    | 66.42                   | 70.69   |
| GLM-4          | 76.63                        | 66.66                    | 67.70                   | 70.33   |
| Qwen-max       | 70.77                        | 64.88                    | 63.84                   | 67.50   |
| GLM-3-Turbo    | 75.21                        | 60.52                    | 59.77                   | 65.17   |
| Qwen-72B-Chat  | 71.25                        | 61.48                    | 59.80                   | 64.18   |
| Yi-34B-Chat    | 72.66                        | 61.33                    | 58.36                   | 64.12   |
| Qwen-14B-Chat  | 69.51                        | 56.53                    | 57.38                   | 61.14   |
| ERNIE-Bot      | 68.81                        | 57.80                    | 51.47                   | 59.36   |
| GPT-4          | 66.11                        | 55.11                    | 47.38                   | 56.20   |
| Qwen-7B-Chat   | 62.74                        | 48.76                    | 44.97                   | 52.16   |
| Yi-6B-Chat     | 60.70                        | 47.79                    | 39.49                   | 51.33   |
| Baichuan2-7B-Chat | 64.38                    | 46.77                    | 40.33                   | 50.49   |
| Baichuan2-13B-Chat | 65.57                    | 49.24                    | 35.40                   | 50.07   |
| ChatGLM3-6B    | 58.04                        | 43.01                    | 39.73                   | 46.93   |
| Xunzi-Qwen-Chat| 60.20                        | 44.31                    | 30.87                   | 45.13   |
| GPT-3.5 Turbo  | 53.50                        | 43.72                    | 36.94                   | 44.72   |
| LLaMA2-70B      | 33.55                        | 36.29                    | 30.72                   | 33.54   |


#### Five-shot AO
| æ¨¡å‹          | åŸºç¡€å†å²çŸ¥è¯† | çŸ­æ–‡æœ¬ç†è§£ | é•¿æ–‡æœ¬ç†è§£ | å¹³å‡å€¼ |
|------------------|:------------------------------:|:--------------------------:|:-------------------------:|:---------:|
| ERNIE-Bot 4.0    | 75.69                        | 69.59                    | 66.12                   | 70.47   |
| GLM-4            | 74.89                        | 65.48                    | 69.07                   | 69.81   |
| Qwen-max         | 75.29                        | 65.48                    | 66.99                   | 69.25   |
| GLM-3-Turbo      | 72.99                        | 59.48                    | 59.66                   | 64.04   |
| Qwen-72B-Chat    | 71.67                        | 61.30                    | 57.07                   | 63.35   |
| ERNIE-Bot        | 68.81                        | 57.62                    | 50.36                   | 58.93   |
| GPT-4            | 65.91                        | 58.07                    | 48.36                   | 57.45   |
| Qwen-14B-Chat    | 70.60                        | 53.73                    | 45.91                   | 56.75   |
| Yi-34B-Chat      | 66.62                        | 52.57                    | 41.90                   | 53.70   |
| Baichuan2-7B-Chat | 63.37                    | 45.91                    | 39.94                   | 49.74   |
| Baichuan2-13B-Chat | 63.75                    | 45.86                    | 32.74                   | 47.45   |
| Qwen-7B-Chat     | 61.42                        | 45.98                    | 30.78                   | 46.06   |
| ChatGLM3-6B      | 55.74                        | 42.92                    | 38.45                   | 45.71   |
| GPT-3.5 Turbo    | 53.99                        | 43.21                    | 36.40                   | 44.54   |
| Xunzi-Qwen-Chat  | 51.30                        | 41.25                    | 29.84                   | 40.80   |
| Yi-6B-Chat       | 55.76                        | 35.97                    | 28.48                   | 40.07   |




#### Zero-shot COT
| æ¨¡å‹          | åŸºç¡€å†å²çŸ¥è¯† | çŸ­æ–‡æœ¬ç†è§£ | é•¿æ–‡æœ¬ç†è§£ | å¹³å‡å€¼ |
|---------------|:------------------------------:|:--------------------------:|-------------------------:|---------:|
| Qwen-max      | 75.10                        | 66.72                    | 61.03                   | 67.62   |
| Qwen-72B-Chat | 74.79                        | 65.25                    | 56.78                   | 65.61   |
| Qwen-14B-Chat | 67.51                        | 54.64                    | 46.12                   | 56.09   |
| Qwen-7B-Chat  | 61.54                        | 44.97                    | 40.21                   | 48.91   |

#### Five-shot COT
| æ¨¡å‹          | åŸºç¡€å†å²çŸ¥è¯† | çŸ­æ–‡æœ¬ç†è§£ | é•¿æ–‡æœ¬ç†è§£ | å¹³å‡å€¼ |
|---------------|:------------------------------:|:--------------------------:|:-------------------------|:---------:|
| Qwen-max      | 74.30                        | 65.94                    | 61.46                   | 67.23   |
| Qwen-72B-Chat | 71.79                        | 61.62                    | 57.66                   | 63.69   |
| Qwen-14B-Chat | 67.49                        | 51.51                    | 39.93                   | 52.97   |
| Qwen-7B-Chat  | 59.37                        | 47.71                    | 35.36                   | 47.48   |


## æ•°æ®

#### ä¸‹è½½
* æ–¹æ³•ä¸€ï¼šä¸‹è½½zipå‹ç¼©æ–‡ä»¶ï¼ˆæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥ç”¨æµè§ˆå™¨æ‰“å¼€ä¸‹é¢çš„é“¾æ¥ï¼‰ï¼š
  ```
  wget https://huggingface.co/datasets/yuting-wei/aceval/resolve/main/aceval.zip
  ```
  ç„¶åå¯ä»¥ä½¿ç”¨ pandasåŠ è½½æ•°æ®ï¼š
  ```python
  import os
  import pandas as pd
  
  File_Dir="aceval"
  test_df=pd.read_csv(os.path.join(File_Dir,"test","art_and_cultural_heritage.csv"))
  ```

* æ–¹æ³•äºŒï¼šä½¿ç”¨[Hugging Face datasets](https://huggingface.co/datasets/yuting-wei/aceval)ç›´æ¥åŠ è½½æ•°æ®é›†ã€‚ç¤ºä¾‹å¦‚ä¸‹ï¼š

  ```python
  from datasets import load_dataset

  dataset=load_dataset(r"yuting-wei/aceval",name="art_and_cultural_heritage")
  ```

#### æ•°æ®æ ¼å¼
ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨ï¼Œæˆ‘ä»¬æ•´ç†äº†13ä¸ªä¸»é¢˜å¯¹åº”çš„ç±»åˆ«å’Œä¸­è‹±æ–‡åç§°ã€‚è¯¦æƒ…è¯·å‚è€ƒ[subject_mapping.json](https://github.com/yuting-wei/AC-EVAL/tree/main/subject_mapping.json)ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
  ```
  {
      "art_and_cultural_heritage": {
        "English": "Art and Cultural Heritage",
        "Chinese": "è‰ºæœ¯å’Œæ–‡åŒ–é—äº§",
        "Supercategory": "General Historical Knowledge"
      },
      ...
      "filename":{
          "English": English Name,
          "Chinese": Chinese Name,
          "Supercatagory": Supercatagory Label (General Historical Knowledge/Short Text Understanding/Long Text Understanding)"
      }
  }
  ```
æ¯ä¸ªä¸»é¢˜çš„æ•°æ®é›†ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼šdevå’Œtestã€‚æ¯ä¸ªä¸»é¢˜çš„devé›†ç”±äº”ä¸ªç¤ºä¾‹ç»„æˆï¼Œå¹¶å¸¦æœ‰ç›¸åº”çš„ç­”æ¡ˆè§£æã€‚testé›†ç”¨äºæ¨¡å‹è¯„ä¼°ï¼Œå…¶æ ‡ç­¾ä¸ºéå…¬å¼€çš„ï¼Œç”¨æˆ·éœ€è¦æäº¤ç»“æœæ‰èƒ½è·å¾—æµ‹è¯•å‡†ç¡®æ€§ã€‚ [å¦‚ä½•æäº¤ï¼Ÿ](#how-to-submit)

ä¸‹é¢æ˜¯ è‰ºæœ¯å’Œæ–‡åŒ–ä¼ æ‰¿ çš„devé›†ç¤ºä¾‹ï¼š
| é—®é¢˜ | A | B | C | D | ç­”æ¡ˆ | è§£æ |
|----------|---|---|---|---|--------|-------------|
| äº”ä»£å—å”æ—¶æœŸè‘—åç”»å®¶é¡¾é—³ä¸­çš„ç»˜ç”»åä½œæ˜¯ï¼Ÿ|ã€Šå¥³å²ç®´å›¾ã€‹ | ã€Šäº”ç‰›å›¾ã€‹ | ã€Šç°ªèŠ±ä»•å¥³å›¾ã€‹| ã€ŠéŸ©ç†™è½½å¤œå®´å›¾ã€‹| D | é¡¾é—³ä¸­çš„ç»˜ç”»åä½œæ˜¯ã€ŠéŸ©ç†™è½½å¤œå®´å›¾ã€‹ã€‚ã€Šäº”ç‰›å›¾ã€‹æ˜¯éŸ©æ»‰çš„ä½œå“ï¼Œã€Šç°ªèŠ±ä»•å¥³å›¾ã€‹æ˜¯å‘¨æ˜‰çš„ä½œå“ï¼Œã€Šå¥³å²ç®´å›¾ã€‹æ˜¯é¡¾æºä¹‹çš„ä½œå“ã€‚ |


## å¦‚ä½•åœ¨AC-EVALä¸Šæµ‹è¯•

æˆ‘ä»¬ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è‡ªåŠ¨æå–ç­”æ¡ˆé€‰é¡¹(A,B,C,D)ï¼Œæ¨¡å‹çš„è¯„ä¼°ä»£ç ä½äº[src](src)ç›®å½•ä¸­ã€‚

æˆ‘ä»¬ä½¿ç”¨äº†ä»¥ä¸‹promptè¿›è¡Œæµ‹è¯•ï¼š
#### ä»…é¢„æµ‹ç­”æ¡ˆçš„prompt
##### Zero-shot AO
```
ä»¥ä¸‹æ˜¯ä¸­å›½å¤ä»£{ä¸»é¢˜}é¢†åŸŸçš„å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ç›´æ¥ç»™å‡ºæ­£ç¡®ç­”æ¡ˆå¯¹åº”çš„é€‰é¡¹ã€‚

{æµ‹è¯•é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆï¼š
```

##### Few-shot AO
```
ä»¥ä¸‹æ˜¯ä¸­å›½å¤ä»£{ä¸»é¢˜}é¢†åŸŸçš„å•é¡¹é€‰æ‹©é¢˜ç¤ºä¾‹ã€‚åœ¨æŸ¥çœ‹è¿™äº›ç¤ºä¾‹ä¹‹åï¼Œè¯·ç›´æ¥ç»™å‡ºæ¥ä¸‹æ¥ä¸€é“é¢˜ç›®çš„æ­£ç¡®ç­”æ¡ˆæ‰€å¯¹åº”çš„é€‰é¡¹ã€‚

ç¤ºä¾‹1ï¼š{é¢˜ç›®1}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆï¼šA

[k-shot demo, note that k is 0 in the zero-shot case]

{æµ‹è¯•é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆï¼š
```

#### æ€ç»´é“¾prompt
##### Zero-shot COT
```
ä»¥ä¸‹æ˜¯ä¸­å›½å¤ä»£{ä¸»é¢˜}é¢†åŸŸçš„å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·é€æ­¥åˆ†æå¹¶ç»™å‡ºæ­£ç¡®ç­”æ¡ˆå¯¹åº”çš„é€‰é¡¹ã€‚

{æµ‹è¯•é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆï¼š
```
##### Few-shot COT
```
ä»¥ä¸‹æ˜¯ä¸­å›½å¤ä»£{ä¸»é¢˜}é¢†åŸŸçš„å•é¡¹é€‰æ‹©é¢˜ç¤ºä¾‹ã€‚åœ¨æŸ¥çœ‹è¿™äº›ç¤ºä¾‹ä¹‹åï¼Œè¯·é€æ­¥åˆ†ææ¥ä¸‹æ¥ä¸€é“é¢˜ç›®å¹¶ç»™å‡ºæ­£ç¡®ç­”æ¡ˆæ‰€å¯¹åº”çš„é€‰é¡¹ã€‚

ç¤ºä¾‹1ï¼š{é¢˜ç›®1}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆè§£æï¼š
è®©æˆ‘ä»¬é€æ­¥åˆ†æã€‚{è§£æè¿‡ç¨‹}
æ‰€ä»¥ç­”æ¡ˆæ˜¯Aã€‚

[k-shot demo, note that k is 0 in the zero-shot case]

{æµ‹è¯•é¢˜ç›®}
A. {é€‰é¡¹A}
B. {é€‰é¡¹B}
C. {é€‰é¡¹C}
D. {é€‰é¡¹D}
ç­”æ¡ˆï¼š
```

## å¦‚ä½•

æ‚¨é¦–å…ˆéœ€è¦å‡†å¤‡ä¸€ä¸ª UTF-8 ç¼–ç çš„ JSON æ–‡ä»¶ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç¼–å†™ã€‚è¯¦æƒ…è¯·å‚è€ƒ[submission_example.json](https://github.com/yuting-wei/AC-EVAL/tree/main/submission_example.json)ã€‚

  ```
  {
      "historical_facts": {
          "0": "A",
          "1": "B",
          "2": "B",
          ...
      },
      
      "subject_name":{
      "0":"ans_0",
      "1":"ans_1",
      ...
      }
      ....
  }
  ```
  ç„¶åï¼Œæ‚¨å¯ä»¥å°†å‡†å¤‡å¥½çš„JSONæ–‡ä»¶æäº¤åˆ°é‚®ç®±(yuting_wei@bupt.edu.cn)ã€‚è¯·åœ¨ç”µå­é‚®ä»¶ä¸»é¢˜ä¸­ä½¿ç”¨ä»¥ä¸‹å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶æ ‡ç­¾æ¥æŒ‡æ˜æ‚¨è¿›è¡Œçš„å®éªŒç±»å‹ï¼š[zero-shot-AOã€few-shot-AOã€zero-shot-COTã€few-shot-COT]ã€‚

## TODO

- [x] åœ¨`src`ç§æ·»åŠ è¯„ä¼°ä»£ç 
- [x] æ·»åŠ æ¨¡å‹çš„ç»†åˆ†ç»“æœ
- [x] é›†æˆåˆ°Hugging Faceæ•°æ®é›†


## Licenses

[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)

æœ¬é¡¹ç›®éµå¾ª[MIT License](https://lbesson.mit-license.org/).

[![CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](http://creativecommons.org/licenses/by-nc-sa/4.0/)

AC-EVALæ•°æ®é›†éµå¾ª [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).


## å¼•ç”¨

å¦‚æœæ‚¨ä½¿ç”¨äº†æˆ‘ä»¬çš„æ•°æ®é›†ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ã€‚
```
@inproceedings{wei-etal-2024-ac,
    title = "{AC}-{EVAL}: Evaluating {A}ncient {C}hinese Language Understanding in Large Language Models",
    author = "Wei, Yuting  and Xu, Yuanxing  and Wei, Xinru  and Yang, Simin  and Zhu, Yangfu  and Li, Yuqing  and Liu, Di  and Wu, Bin",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    year = "2024",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.87",
    pages = "1600--1617",
}

```
## è‡´è°¢

æœ¬é¡¹ç›®å€Ÿé‰´äº†[C-Eval](https://github.com/hkust-nlp/ceval)çš„æ•´ä½“ç»“æ„ã€‚æˆ‘ä»¬å¯¹å…¶å›¢é˜Ÿçš„è¾›å‹¤å·¥ä½œä»¥åŠå¯¹ç¤¾åŒºä½œå‡ºçš„é‡è¦è´¡çŒ®è¡¨ç¤ºè¡·å¿ƒçš„æ„Ÿè°¢ã€‚
